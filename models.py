'''
https://huggingface.co/transformers/v3.3.1/pretrained_models.html

bert:
bert-base-uncased	110M
bert-large-uncased	340M

roberta:
roberta-base	125M
roberta-large	355M

gpt2:
gpt2 (124M), gpt2-medium (355M), gpt2-large (774M), gpt2-xl (1558M~1.5B)



OPTForCausalLMs:
"facebook/opt-125m" (125M) "facebook/opt-350m" (350M), "facebook/opt-1.3B" (1.3B), "facebook/opt-2.7B" (2.7B), "facebook/opt-6.7B" (6.7B), "facebook/opt-13B" (13B)

roberta:
roberta-base (125M), roberta-large(355M)

llama:

meta-llama/Llama-2-7b
meta-llama/Llama-2-7b-chat
'''